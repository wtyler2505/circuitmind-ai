1. **Zoom Controls & Canvas Scaling** While the application state includes a zoom: 1 property and displays 100% in the bottom-right of the toolbar, there is currently no way to actually change the zoom level. What needs to be done: Implement onWheel event handlers on the SVG canvas to allow zooming in and out using the scroll wheel (while holding Ctrl/Cmd), and add dedicated \+ and \- zoom buttons in the UI for accessibility. The pan function must also be updated to account for dynamic zoom scaling during drag calculations.  
2. Visual Resizing & Transform Inputs Currently, users can drag to move elements and click a button to rotate them 90 degrees, but they cannot resize elements once they are placed. What needs to be done: Add bounding-box resize handles (small squares on the corners/edges of the selection outline) to allow dragging to scale widths and heights. Additionally, the X (Rel) and Y (Rel) inputs in the Properties panel are currently hardcoded to . These should be wired up to state so users can type in precise pixel coordinates for exact positioning.  
3. Layer Ordering (Z-Index Management) & Grouping In SVG, the visual stacking order (Z-index) is determined purely by the order of elements in the DOM. Right now, elements are rendered in the order they are created. What needs to be done: The "Layers" panel needs up/down arrows or drag-and-drop functionality to reorder elements in the state.elements array (Bring Forward, Send Backward). Furthermore, while the data structure supports groups (type: 'g'), there are no UI buttons to Group or Ungroup selected items, which is essential for managing complex component symbols.  
4. Vector Node / Path Editing The PenTool (path tool) successfully allows users to click and draw continuous lines, closing them on double-click. However, once a path is drawn, it becomes a static object. What needs to be done: Add a "Direct Selection" or "Node Edit" sub-tool. When a path is selected, it should reveal the individual vertices (points) and allow the user to drag specific nodes to reshape the path, rather than just moving the entire path block as a single unit.  
5. Backend Integration & Real-Time Collaboration There is a major disconnect between the app's architectural files and its actual execution. The metadata.json advertises "real-time collaboration tools," and the database/schema.sql file outlines a robust PostgreSQL database with user authentication, cloud syncing, and version history. However, the app currently only uses local browser storage (idb via services/db.ts). What needs to be done: Connect the frontend to an actual backend API. Implement user authentication, switch the save/load logic to persist to the PostgreSQL database, and implement WebSockets or a CRDT framework (like Yjs) to enable the promised multi-user real-time collaboration.

Core UX & Workflow

1. Marquee / Rubber-Band Selection Current State: The select tool relies entirely on clicking individual elements or holding Shift to toggle selection. The Gap: There is no "click and drag" box selection to select multiple items at once. This is a fundamental expectation for any graphics editor. Without it, selecting a complex group of 20 lines requires 20 individual clicks.  
2. Copy, Paste, and Duplicate Current State: The code imports Copy from lucide-react, but it is never used. The handleKeyDown function handles Delete, Undo, Redo, and Save, but has no logic for Ctrl+C (Copy), Ctrl+V (Paste), or Ctrl+D (Duplicate). The Gap: Users cannot duplicate elements. If they need two resistors, they have to drag two templates from the library or redraw them manually.  
3. Object Snapping & Alignment Guides Current State: The app has snapToGrid logic (Math.round(val / gridSize) \* gridSize). The Gap: It lacks Object Snapping (Smart Guides). Professional editors show visual guidelines when the edge or center of the moving object aligns with the edge/center of another object. This is critical for schematic diagrams where alignment implies connection.  
4. Primitive Text Editing Current State: Text creation uses window.prompt("Enter Text:", "Label"). This blocks the main thread and offers a terrible UX. The Gap: Text editing should happen either: In-place (WYSIWYG): Double-clicking text turns it into a contenteditable span overlay. Sidebar: A live-updating text area in the properties panel. Bonus: There are no controls for font-family, font-weight, or text-anchor (alignment), which are present in the TEMPLATES data but uneditable in the UI. Vector & Graphics Capabilities  
5. Bezier Curves (The Pen Tool is actually a Polyline Tool) Current State: The path tool captures clicks and pushes points to an array, creating straight lines (L commands). The Gap: A true "Pen Tool" supports Bezier Curves (C or Q commands). Users need to be able to click-and-drag to pull out control handles to create smooth curves, which is essential for drawing accurate component bodies (e.g., inductors, coils).  
6. Stroke Styling (Caps & Joins) Current State: The app controls stroke color, width, and dasharray. The Gap: SVG supports stroke-linecap (butt, round, square) and stroke-linejoin (miter, round, bevel). Without stroke-linecap: round, lines drawn for electronics (wires) look jagged and unprofessional at the ends.  
7. Boolean Operations (Constructive Geometry) Current State: Shapes are independent. The Gap: Users cannot combine shapes. Professional vector tools allow Union, Subtract, Intersect, and Exclude. For example, creating a custom shield shape often requires subtracting a circle from a rectangle.  
8. Ordering of Elements (Z-Index) Current State: Elements render in the order they exist in the array. The Gap: There are no "Bring to Front" or "Send to Back" controls. If a user draws a background rectangle after drawing the text, the text is hidden behind the rectangle with no way to fix it other than deleting and redrawing. Electronics / CAD Specific Features  
9. Bulk Pin Manager Current State: Pins must be selected one by one to edit their label or type. The Gap: Electronic symbols often have 64+ pins (e.g., a microcontroller). The app needs a Pin Table view where users can bulk-edit pin numbers, names, and electrical types in a spreadsheet-like interface.  
10. Symbol Origin Marker (Anchor Point) Current State: The grid is infinite, and coordinates are arbitrary based on where the user clicks. The Gap: CAD symbols require a defined (0,0) Origin Point. This is the point where the mouse cursor attaches when placing the component in a schematic tool (like KiCad or Altium). The app needs a visual crosshair indicating the origin, and a way to "Set Origin" relative to the drawing. Technical & Architecture  
11. Export Format Options Current State: The app exports raw SVG and a basic .kicad\_sym text file. The Gap: PNG/JPG Export: Users cannot download a raster image for documentation. KiCad Improvements: The current KiCad export uses a naive unit conversion (\* 0.0254) and doesn't handle proper Pin Stacking, arcs, or polygons correctly.  
12. Color Palette Management Current State: The color picker is a native . The Gap: Professional tools have a Swatch Library. Users need to define "Schematic Colors" (e.g., "Signal Green", "Power Red") and reuse them to ensure consistency across the library.  
13. History/State Visualization Current State: Undo/Redo exists but is invisible. The Gap: A History Panel showing a list of actions (e.g., "Moved Rectangle", "Changed Fill", "Added Pin") allows users to jump back to a specific state, which is a standard feature in tools like Photoshop or Figma.  
14. Canvas Context Menu Current State: Right-click context is handled by the browser default (Save Image, Inspect). The Gap: A custom Right-Click Menu is essential for productivity. It should offer context-sensitive actions: "Delete", "Duplicate", "Lock", "Properties", or "Reset View".  
15. Autosave to LocalStorage Current State: The app uses IndexedDB via idb to save Projects explicitly when the user clicks "Save". The Gap: If the browser crashes or the tab is closed before clicking "Save", work is lost. Implementing a localStorage or IndexedDB autosave of the current working state (separate from the saved project files) is a critical safety feature.

Current Integration Analysis How well is it integrated? Poorly. The AI is currently a "sidecar" attachment. It lives in the rightPanel, takes a snapshot of the DOM, sends it away, and pastes the result back in as a generic blob. It is not integrated into the application's logic, state management, or tool system. What can it do? Generate New Geometry: It can create new SVG shapes (paths, rects, circles) based on a text prompt or an image. Parse Pins (Regex): It can detect specific HTML comments () in the generated text and convert them into the app's internal "Pin" data structure. Read Context (Superficially): It receives the current innerHTML of the SVG canvas, so it "knows" what is visually there, but only as a giant string of text. What can it NOT do? Modify Existing Elements: It cannot change the color, size, or position of an element you have already drawn. Delete Elements: It cannot remove anything. Select Elements: It cannot change your selection. Change App State: It cannot switch tools, zoom, pan, toggle grid, or save the project. Understand Structure: It sees \<rect x="10"...\> but doesn't know that rect is "Resistor R1" or that it is locked. Multi-step Tasks: It cannot perform complex workflows (e.g., "Create a grid of 5 resistors spaced 10px apart"). What can it see? The Rendered Output: It sees svgRef.current.innerHTML. This is the end result of the React render, not the source of truth (the React State). User Inputs: The prompt text and uploaded image. What can it manipulate? Nothing directly. It returns a string. The applyAiSvg function in App.tsx takes that string and appends it to the element list. The AI itself has no "hands" inside the app logic. What can it change? It can only add to the elements array and the pins array. What are its permissions? It has no special permissions within the app structure. It is effectively a "Read-Only" observer that can suggest "Append Only" operations. Current Score: 2.5 / 10 It functions as a "Clip Art Generator," but fails as an "Assistant." Roadmap to "God Mode" (Full Integration) To get the AI to the point where it can do anything a human can do (and more), you must shift from Generative Content (returning text) to Function Calling (returning actions). Here is the exact technical roadmap to achieve 10/10 integration:

1. Switch to "Function Calling" (The Agent Pattern) Instead of asking Gemini to "Generate XML," you must configure Gemini with a list of tools. The AI should not return text; it should return a request to execute a function. Define these tools for the AI: createElements(elements: SVGElementData\[\]) updateElements(ids: string\[\], updates: Partial) deleteElements(ids: string\[\]) selectElements(ids: string\[\]) setTool(tool: ToolType) setViewport(zoom: number, pan: Point) saveProject() undo()  
2. Give the AI "Source of Truth" Vision Stop sending innerHTML. The DOM is messy and lacks metadata. Change: Serialize the AppState (specifically elements, selectedIds, and pins) into a clean JSON format. Why: The AI needs to know IDs (el-123), logical names ("Resistor"), and lock states to manipulate them correctly.  
3. Implement the "Executor" Middleware You need a translation layer in App.tsx that handles the AI's response. Current Flow: AI Response (String) \-\> innerHTML Injection. New Flow: AI Response (Function Call) \-\> switch/case \-\> setState. Example "God Mode" interaction: User: "Make all the resistors red and move them to the right." AI Logic: Analyzes state JSON. Finds elements with name: "Resistor". Calls updateElements(\['el-1', 'el-5'\], { attrs: { fill: 'red' } }). Calls moveElements(\['el-1', 'el-5'\], { dx: 100, dy: 0 }). Executor: Receives these calls and performs setState updates.  
4. Semantic element tagging The AI struggles to edit things because currently, a resistor is just a bunch of lines. Change: When creating elements, add a metadata field semanticType: 'resistor' | 'capacitor'. Result: The AI can query "Find all capacitors" reliably instead of guessing based on shape.  
5. Context-Aware Prompting (The Selection Context) The prompt system needs to implicitly include the user's intent based on UI state. If selectedIds.length \> 0: System prompt should append "User is referring to elements \[el-1, el-2\]". If tool \=== 'path': System prompt should append "User is currently drawing a path."  
6. Multi-Turn Conversations (Memory) Currently, aiMessages is just a display log. The full conversation history must be sent back to Gemini with every request. Why: Allows for: User: "Draw a box." (AI draws box) User: "Make it bigger." (AI knows "it" refers to the box from the previous turn).  
7. Error Correction Loop If the AI generates invalid SVG or tries to delete a non-existent ID, the app should catch the error and feed it back to the AI. App: "Error: ID 'el-99' not found." AI: "Apologies, I will list the elements again to find the correct ID." Summary of Necessary Code Changes types.ts: Define AIAction types (Create, Update, Delete, Select). geminiService.ts: Rewrite generateSvgFromPrompt to use tools and functionDeclarations instead of just text generation. App.tsx: Create a executeAiAction function that wraps setState. Pass a simplified version of state.elements (stripped of heavy strings) to the AI context. Handle the "Thinking" state where the AI might chain multiple function calls together.

